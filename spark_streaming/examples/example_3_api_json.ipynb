{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carsofferrei/04_data_processing/blob/main/spark_streaming/examples/example_3_api_json.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_GBE9UsyxwK"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9LeYFsPTjAb"
      },
      "source": [
        "# Setting up PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYXeODL0T1fO",
        "outputId": "b805aca4-2d12-47de-d985-2b8a22eeb565"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "%pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "637HFw00T3LP"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.master('local').appName('Test streaming').getOrCreate()\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm -rf /content/landing\n",
        "#!rm -rf /content/bronze\n",
        "!mkdir -p /content/landing"
      ],
      "metadata": {
        "id": "aF7fzyYIJi0l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simulate producer:\n",
        "- extract data from API\n",
        "- store data as json in the lake\n",
        "- run task async"
      ],
      "metadata": {
        "id": "RZdHGoFyTlMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pyspark.sql.types import *\n",
        "import json\n",
        "import datetime\n",
        "import asyncio\n",
        "\n",
        "async def ingest_from_api(url: str, table: str, schema: StructType = None):\n",
        "  response = requests.get(url)\n",
        "  timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "  if response.status_code == 200:\n",
        "    data = response.json()\n",
        "    with open(f\"/content/landing/{table}_{int(timestamp)}.json\", \"w\") as f:\n",
        "      #como estamos a utilizar código python, precisamos de criar a pasta para guardar o conteudo (mkdir acima)\n",
        "        json.dump(data, f)\n",
        "\n",
        "async def producer(loop: int, interval_time: int):\n",
        "  for i in range(loop):\n",
        "    await ingest_from_api(\"https://api.carrismetropolitana.pt/vehicles\", \"vehicles\")\n",
        "    await ingest_from_api(\"https://api.carrismetropolitana.pt/lines\", \"lines\")\n",
        "    await asyncio.sleep(interval_time)\n",
        "    # Garantir que o processo dá a si próprio o periodo de cadência para que também não sejamos bloqueados do lado da API\n",
        "\n",
        "async def main():\n",
        "  asyncio.create_task(producer(10, 30))\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "id": "tTQhp8UbFUCl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Read from /content/landing as streaming\n",
        "- store data in memory (for testing)\n",
        "- store data in the bronze layer"
      ],
      "metadata": {
        "id": "kIqHdZEKUEmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "vehicle_schema = StructType([StructField('bearing', IntegerType(), True),\n",
        "                             StructField('block_id', StringType(), True),\n",
        "                             StructField('current_status', StringType(), True),\n",
        "                             StructField('id', StringType(), True),\n",
        "                             StructField('lat', FloatType(), True),\n",
        "                             StructField('line_id', StringType(), True),\n",
        "                             StructField('lon', FloatType(), True),\n",
        "                             StructField('pattern_id', StringType(), True),\n",
        "                             StructField('route_id', StringType(), True),\n",
        "                             StructField('schedule_relationship', StringType(), True),\n",
        "                             StructField('shift_id', StringType(), True),\n",
        "                             StructField('speed', FloatType(), True),\n",
        "                             StructField('stop_id', StringType(), True),\n",
        "                             StructField('timestamp', TimestampType(), True),\n",
        "                             StructField('trip_id', StringType(), True)])\n",
        "\n",
        "stream = spark.readStream.format(\"json\").schema(vehicle_schema).load(\"/content/landing/vehicles*\")\n",
        "\n",
        "dedup = stream.dropDuplicates()"
      ],
      "metadata": {
        "id": "_dTSf527Fhy0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Questionar se estou a trabalhar com Streaming para o Spark\n",
        "dedup.isStreaming"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2i_5Fqiufhoy",
        "outputId": "48b3f5b4-3b43-4b5f-d0e0-bccd7aa8e231"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using memory for testing\n",
        "try:\n",
        "  if query.isActive:\n",
        "    query.stop()\n",
        "except:\n",
        "  pass\n",
        "\n",
        "# Spark não permite que duas querys streaming com o mesmo nome estejam ativas na mesma sessão\n",
        "# Vai retornar uma query streaming. Se estiver ativa, dámos um stop.\n",
        "\n",
        "# Estamos a basear-nos no formato memory - mais utilizado para testes.\n",
        "# Quando uso o memory, tenho vários formatos e neste caso estamos a renomear o nome queryName para vehicles.\n",
        "query = (dedup.writeStream.format(\"memory\").option(\"queryName\", \"vehicles\").start())"
      ],
      "metadata": {
        "id": "9N99eI41UUFA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mensagem da query que estava a ser executada\n",
        "query.status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94KmUqzbghIU",
        "outputId": "b81130e4-b09c-4179-be19-219609702e94"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'message': 'Getting offsets from FileStreamSource[file:/content/landing/vehicles*]',\n",
              " 'isDataAvailable': False,\n",
              " 'isTriggerActive': True}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# validar quantos batchs já temos, o que está dentro de cada batch, se já consumimos todos os dados que estao dentro\n",
        "# dos eventos (a partir desta info: numInputRows)\n",
        "query.recentProgress"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ1X2IABhEy3",
        "outputId": "216e2ba9-7198-42cf-a353-da5f0f89b5d1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': '9b6735d5-3fec-421b-8678-477c99ca09d7',\n",
              "  'runId': '92114148-97d0-4abc-83c7-8d3619a25d83',\n",
              "  'name': 'vehicles',\n",
              "  'timestamp': '2024-11-30T09:58:32.632Z',\n",
              "  'batchId': 0,\n",
              "  'numInputRows': 4021,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 116.39889998552611,\n",
              "  'durationMs': {'addBatch': 32634,\n",
              "   'commitOffsets': 37,\n",
              "   'getBatch': 255,\n",
              "   'latestOffset': 173,\n",
              "   'queryPlanning': 1139,\n",
              "   'triggerExecution': 34540,\n",
              "   'walCommit': 226},\n",
              "  'stateOperators': [{'operatorName': 'dedupe',\n",
              "    'numRowsTotal': 3607,\n",
              "    'numRowsUpdated': 3607,\n",
              "    'allUpdatesTimeMs': 10613,\n",
              "    'numRowsRemoved': 0,\n",
              "    'allRemovalsTimeMs': 7,\n",
              "    'commitTimeMs': 10145,\n",
              "    'memoryUsedBytes': 1580112,\n",
              "    'numRowsDroppedByWatermark': 0,\n",
              "    'numShufflePartitions': 200,\n",
              "    'numStateStoreInstances': 200,\n",
              "    'customMetrics': {'loadedMapCacheHitCount': 0,\n",
              "     'loadedMapCacheMissCount': 0,\n",
              "     'numDroppedDuplicateRows': 414,\n",
              "     'stateOnCurrentVersionSizeBytes': 1551312}}],\n",
              "  'sources': [{'description': 'FileStreamSource[file:/content/landing/vehicles*]',\n",
              "    'startOffset': None,\n",
              "    'endOffset': {'logOffset': 0},\n",
              "    'latestOffset': None,\n",
              "    'numInputRows': 4021,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 116.39889998552611}],\n",
              "  'sink': {'description': 'MemorySink', 'numOutputRows': 3607}},\n",
              " {'id': '9b6735d5-3fec-421b-8678-477c99ca09d7',\n",
              "  'runId': '92114148-97d0-4abc-83c7-8d3619a25d83',\n",
              "  'name': 'vehicles',\n",
              "  'timestamp': '2024-11-30T09:59:17.193Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 5, 'triggerExecution': 6},\n",
              "  'stateOperators': [{'operatorName': 'dedupe',\n",
              "    'numRowsTotal': 3607,\n",
              "    'numRowsUpdated': 0,\n",
              "    'allUpdatesTimeMs': 10613,\n",
              "    'numRowsRemoved': 0,\n",
              "    'allRemovalsTimeMs': 7,\n",
              "    'commitTimeMs': 10145,\n",
              "    'memoryUsedBytes': 1580112,\n",
              "    'numRowsDroppedByWatermark': 0,\n",
              "    'numShufflePartitions': 200,\n",
              "    'numStateStoreInstances': 200,\n",
              "    'customMetrics': {'loadedMapCacheHitCount': 0,\n",
              "     'loadedMapCacheMissCount': 0,\n",
              "     'numDroppedDuplicateRows': 414,\n",
              "     'stateOnCurrentVersionSizeBytes': 1551312}}],\n",
              "  'sources': [{'description': 'FileStreamSource[file:/content/landing/vehicles*]',\n",
              "    'startOffset': {'logOffset': 0},\n",
              "    'endOffset': {'logOffset': 0},\n",
              "    'latestOffset': None,\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0}],\n",
              "  'sink': {'description': 'MemorySink', 'numOutputRows': 0}},\n",
              " {'id': '9b6735d5-3fec-421b-8678-477c99ca09d7',\n",
              "  'runId': '92114148-97d0-4abc-83c7-8d3619a25d83',\n",
              "  'name': 'vehicles',\n",
              "  'timestamp': '2024-11-30T09:59:27.203Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 4, 'triggerExecution': 4},\n",
              "  'stateOperators': [{'operatorName': 'dedupe',\n",
              "    'numRowsTotal': 3607,\n",
              "    'numRowsUpdated': 0,\n",
              "    'allUpdatesTimeMs': 10613,\n",
              "    'numRowsRemoved': 0,\n",
              "    'allRemovalsTimeMs': 7,\n",
              "    'commitTimeMs': 10145,\n",
              "    'memoryUsedBytes': 1580112,\n",
              "    'numRowsDroppedByWatermark': 0,\n",
              "    'numShufflePartitions': 200,\n",
              "    'numStateStoreInstances': 200,\n",
              "    'customMetrics': {'loadedMapCacheHitCount': 0,\n",
              "     'loadedMapCacheMissCount': 0,\n",
              "     'numDroppedDuplicateRows': 414,\n",
              "     'stateOnCurrentVersionSizeBytes': 1551312}}],\n",
              "  'sources': [{'description': 'FileStreamSource[file:/content/landing/vehicles*]',\n",
              "    'startOffset': {'logOffset': 0},\n",
              "    'endOffset': {'logOffset': 0},\n",
              "    'latestOffset': None,\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0}],\n",
              "  'sink': {'description': 'MemorySink', 'numOutputRows': 0}},\n",
              " {'id': '9b6735d5-3fec-421b-8678-477c99ca09d7',\n",
              "  'runId': '92114148-97d0-4abc-83c7-8d3619a25d83',\n",
              "  'name': 'vehicles',\n",
              "  'timestamp': '2024-11-30T09:59:37.215Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 3, 'triggerExecution': 3},\n",
              "  'stateOperators': [{'operatorName': 'dedupe',\n",
              "    'numRowsTotal': 3607,\n",
              "    'numRowsUpdated': 0,\n",
              "    'allUpdatesTimeMs': 10613,\n",
              "    'numRowsRemoved': 0,\n",
              "    'allRemovalsTimeMs': 7,\n",
              "    'commitTimeMs': 10145,\n",
              "    'memoryUsedBytes': 1580112,\n",
              "    'numRowsDroppedByWatermark': 0,\n",
              "    'numShufflePartitions': 200,\n",
              "    'numStateStoreInstances': 200,\n",
              "    'customMetrics': {'loadedMapCacheHitCount': 0,\n",
              "     'loadedMapCacheMissCount': 0,\n",
              "     'numDroppedDuplicateRows': 414,\n",
              "     'stateOnCurrentVersionSizeBytes': 1551312}}],\n",
              "  'sources': [{'description': 'FileStreamSource[file:/content/landing/vehicles*]',\n",
              "    'startOffset': {'logOffset': 0},\n",
              "    'endOffset': {'logOffset': 0},\n",
              "    'latestOffset': None,\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0}],\n",
              "  'sink': {'description': 'MemorySink', 'numOutputRows': 0}},\n",
              " {'id': '9b6735d5-3fec-421b-8678-477c99ca09d7',\n",
              "  'runId': '92114148-97d0-4abc-83c7-8d3619a25d83',\n",
              "  'name': 'vehicles',\n",
              "  'timestamp': '2024-11-30T09:59:47.228Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 7, 'triggerExecution': 8},\n",
              "  'stateOperators': [{'operatorName': 'dedupe',\n",
              "    'numRowsTotal': 3607,\n",
              "    'numRowsUpdated': 0,\n",
              "    'allUpdatesTimeMs': 10613,\n",
              "    'numRowsRemoved': 0,\n",
              "    'allRemovalsTimeMs': 7,\n",
              "    'commitTimeMs': 10145,\n",
              "    'memoryUsedBytes': 1580112,\n",
              "    'numRowsDroppedByWatermark': 0,\n",
              "    'numShufflePartitions': 200,\n",
              "    'numStateStoreInstances': 200,\n",
              "    'customMetrics': {'loadedMapCacheHitCount': 0,\n",
              "     'loadedMapCacheMissCount': 0,\n",
              "     'numDroppedDuplicateRows': 414,\n",
              "     'stateOnCurrentVersionSizeBytes': 1551312}}],\n",
              "  'sources': [{'description': 'FileStreamSource[file:/content/landing/vehicles*]',\n",
              "    'startOffset': {'logOffset': 0},\n",
              "    'endOffset': {'logOffset': 0},\n",
              "    'latestOffset': None,\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0}],\n",
              "  'sink': {'description': 'MemorySink', 'numOutputRows': 0}},\n",
              " {'id': '9b6735d5-3fec-421b-8678-477c99ca09d7',\n",
              "  'runId': '92114148-97d0-4abc-83c7-8d3619a25d83',\n",
              "  'name': 'vehicles',\n",
              "  'timestamp': '2024-11-30T09:59:57.240Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 3, 'triggerExecution': 3},\n",
              "  'stateOperators': [{'operatorName': 'dedupe',\n",
              "    'numRowsTotal': 3607,\n",
              "    'numRowsUpdated': 0,\n",
              "    'allUpdatesTimeMs': 10613,\n",
              "    'numRowsRemoved': 0,\n",
              "    'allRemovalsTimeMs': 7,\n",
              "    'commitTimeMs': 10145,\n",
              "    'memoryUsedBytes': 1580112,\n",
              "    'numRowsDroppedByWatermark': 0,\n",
              "    'numShufflePartitions': 200,\n",
              "    'numStateStoreInstances': 200,\n",
              "    'customMetrics': {'loadedMapCacheHitCount': 0,\n",
              "     'loadedMapCacheMissCount': 0,\n",
              "     'numDroppedDuplicateRows': 414,\n",
              "     'stateOnCurrentVersionSizeBytes': 1551312}}],\n",
              "  'sources': [{'description': 'FileStreamSource[file:/content/landing/vehicles*]',\n",
              "    'startOffset': {'logOffset': 0},\n",
              "    'endOffset': {'logOffset': 0},\n",
              "    'latestOffset': None,\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0}],\n",
              "  'sink': {'description': 'MemorySink', 'numOutputRows': 0}},\n",
              " {'id': '9b6735d5-3fec-421b-8678-477c99ca09d7',\n",
              "  'runId': '92114148-97d0-4abc-83c7-8d3619a25d83',\n",
              "  'name': 'vehicles',\n",
              "  'timestamp': '2024-11-30T10:00:07.242Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 3, 'triggerExecution': 3},\n",
              "  'stateOperators': [{'operatorName': 'dedupe',\n",
              "    'numRowsTotal': 3607,\n",
              "    'numRowsUpdated': 0,\n",
              "    'allUpdatesTimeMs': 10613,\n",
              "    'numRowsRemoved': 0,\n",
              "    'allRemovalsTimeMs': 7,\n",
              "    'commitTimeMs': 10145,\n",
              "    'memoryUsedBytes': 1580112,\n",
              "    'numRowsDroppedByWatermark': 0,\n",
              "    'numShufflePartitions': 200,\n",
              "    'numStateStoreInstances': 200,\n",
              "    'customMetrics': {'loadedMapCacheHitCount': 0,\n",
              "     'loadedMapCacheMissCount': 0,\n",
              "     'numDroppedDuplicateRows': 414,\n",
              "     'stateOnCurrentVersionSizeBytes': 1551312}}],\n",
              "  'sources': [{'description': 'FileStreamSource[file:/content/landing/vehicles*]',\n",
              "    'startOffset': {'logOffset': 0},\n",
              "    'endOffset': {'logOffset': 0},\n",
              "    'latestOffset': None,\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0}],\n",
              "  'sink': {'description': 'MemorySink', 'numOutputRows': 0}},\n",
              " {'id': '9b6735d5-3fec-421b-8678-477c99ca09d7',\n",
              "  'runId': '92114148-97d0-4abc-83c7-8d3619a25d83',\n",
              "  'name': 'vehicles',\n",
              "  'timestamp': '2024-11-30T10:00:17.249Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 4, 'triggerExecution': 4},\n",
              "  'stateOperators': [{'operatorName': 'dedupe',\n",
              "    'numRowsTotal': 3607,\n",
              "    'numRowsUpdated': 0,\n",
              "    'allUpdatesTimeMs': 10613,\n",
              "    'numRowsRemoved': 0,\n",
              "    'allRemovalsTimeMs': 7,\n",
              "    'commitTimeMs': 10145,\n",
              "    'memoryUsedBytes': 1580112,\n",
              "    'numRowsDroppedByWatermark': 0,\n",
              "    'numShufflePartitions': 200,\n",
              "    'numStateStoreInstances': 200,\n",
              "    'customMetrics': {'loadedMapCacheHitCount': 0,\n",
              "     'loadedMapCacheMissCount': 0,\n",
              "     'numDroppedDuplicateRows': 414,\n",
              "     'stateOnCurrentVersionSizeBytes': 1551312}}],\n",
              "  'sources': [{'description': 'FileStreamSource[file:/content/landing/vehicles*]',\n",
              "    'startOffset': {'logOffset': 0},\n",
              "    'endOffset': {'logOffset': 0},\n",
              "    'latestOffset': None,\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0}],\n",
              "  'sink': {'description': 'MemorySink', 'numOutputRows': 0}},\n",
              " {'id': '9b6735d5-3fec-421b-8678-477c99ca09d7',\n",
              "  'runId': '92114148-97d0-4abc-83c7-8d3619a25d83',\n",
              "  'name': 'vehicles',\n",
              "  'timestamp': '2024-11-30T10:00:27.257Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 6, 'triggerExecution': 6},\n",
              "  'stateOperators': [{'operatorName': 'dedupe',\n",
              "    'numRowsTotal': 3607,\n",
              "    'numRowsUpdated': 0,\n",
              "    'allUpdatesTimeMs': 10613,\n",
              "    'numRowsRemoved': 0,\n",
              "    'allRemovalsTimeMs': 7,\n",
              "    'commitTimeMs': 10145,\n",
              "    'memoryUsedBytes': 1580112,\n",
              "    'numRowsDroppedByWatermark': 0,\n",
              "    'numShufflePartitions': 200,\n",
              "    'numStateStoreInstances': 200,\n",
              "    'customMetrics': {'loadedMapCacheHitCount': 0,\n",
              "     'loadedMapCacheMissCount': 0,\n",
              "     'numDroppedDuplicateRows': 414,\n",
              "     'stateOnCurrentVersionSizeBytes': 1551312}}],\n",
              "  'sources': [{'description': 'FileStreamSource[file:/content/landing/vehicles*]',\n",
              "    'startOffset': {'logOffset': 0},\n",
              "    'endOffset': {'logOffset': 0},\n",
              "    'latestOffset': None,\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0}],\n",
              "  'sink': {'description': 'MemorySink', 'numOutputRows': 0}},\n",
              " {'id': '9b6735d5-3fec-421b-8678-477c99ca09d7',\n",
              "  'runId': '92114148-97d0-4abc-83c7-8d3619a25d83',\n",
              "  'name': 'vehicles',\n",
              "  'timestamp': '2024-11-30T10:00:37.266Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 2, 'triggerExecution': 2},\n",
              "  'stateOperators': [{'operatorName': 'dedupe',\n",
              "    'numRowsTotal': 3607,\n",
              "    'numRowsUpdated': 0,\n",
              "    'allUpdatesTimeMs': 10613,\n",
              "    'numRowsRemoved': 0,\n",
              "    'allRemovalsTimeMs': 7,\n",
              "    'commitTimeMs': 10145,\n",
              "    'memoryUsedBytes': 1580112,\n",
              "    'numRowsDroppedByWatermark': 0,\n",
              "    'numShufflePartitions': 200,\n",
              "    'numStateStoreInstances': 200,\n",
              "    'customMetrics': {'loadedMapCacheHitCount': 0,\n",
              "     'loadedMapCacheMissCount': 0,\n",
              "     'numDroppedDuplicateRows': 414,\n",
              "     'stateOnCurrentVersionSizeBytes': 1551312}}],\n",
              "  'sources': [{'description': 'FileStreamSource[file:/content/landing/vehicles*]',\n",
              "    'startOffset': {'logOffset': 0},\n",
              "    'endOffset': {'logOffset': 0},\n",
              "    'latestOffset': None,\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0}],\n",
              "  'sink': {'description': 'MemorySink', 'numOutputRows': 0}},\n",
              " {'id': '9b6735d5-3fec-421b-8678-477c99ca09d7',\n",
              "  'runId': '92114148-97d0-4abc-83c7-8d3619a25d83',\n",
              "  'name': 'vehicles',\n",
              "  'timestamp': '2024-11-30T10:00:47.267Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 3, 'triggerExecution': 3},\n",
              "  'stateOperators': [{'operatorName': 'dedupe',\n",
              "    'numRowsTotal': 3607,\n",
              "    'numRowsUpdated': 0,\n",
              "    'allUpdatesTimeMs': 10613,\n",
              "    'numRowsRemoved': 0,\n",
              "    'allRemovalsTimeMs': 7,\n",
              "    'commitTimeMs': 10145,\n",
              "    'memoryUsedBytes': 1580112,\n",
              "    'numRowsDroppedByWatermark': 0,\n",
              "    'numShufflePartitions': 200,\n",
              "    'numStateStoreInstances': 200,\n",
              "    'customMetrics': {'loadedMapCacheHitCount': 0,\n",
              "     'loadedMapCacheMissCount': 0,\n",
              "     'numDroppedDuplicateRows': 414,\n",
              "     'stateOnCurrentVersionSizeBytes': 1551312}}],\n",
              "  'sources': [{'description': 'FileStreamSource[file:/content/landing/vehicles*]',\n",
              "    'startOffset': {'logOffset': 0},\n",
              "    'endOffset': {'logOffset': 0},\n",
              "    'latestOffset': None,\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0}],\n",
              "  'sink': {'description': 'MemorySink', 'numOutputRows': 0}},\n",
              " {'id': '9b6735d5-3fec-421b-8678-477c99ca09d7',\n",
              "  'runId': '92114148-97d0-4abc-83c7-8d3619a25d83',\n",
              "  'name': 'vehicles',\n",
              "  'timestamp': '2024-11-30T10:00:57.276Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 2, 'triggerExecution': 2},\n",
              "  'stateOperators': [{'operatorName': 'dedupe',\n",
              "    'numRowsTotal': 3607,\n",
              "    'numRowsUpdated': 0,\n",
              "    'allUpdatesTimeMs': 10613,\n",
              "    'numRowsRemoved': 0,\n",
              "    'allRemovalsTimeMs': 7,\n",
              "    'commitTimeMs': 10145,\n",
              "    'memoryUsedBytes': 1580112,\n",
              "    'numRowsDroppedByWatermark': 0,\n",
              "    'numShufflePartitions': 200,\n",
              "    'numStateStoreInstances': 200,\n",
              "    'customMetrics': {'loadedMapCacheHitCount': 0,\n",
              "     'loadedMapCacheMissCount': 0,\n",
              "     'numDroppedDuplicateRows': 414,\n",
              "     'stateOnCurrentVersionSizeBytes': 1551312}}],\n",
              "  'sources': [{'description': 'FileStreamSource[file:/content/landing/vehicles*]',\n",
              "    'startOffset': {'logOffset': 0},\n",
              "    'endOffset': {'logOffset': 0},\n",
              "    'latestOffset': None,\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0}],\n",
              "  'sink': {'description': 'MemorySink', 'numOutputRows': 0}},\n",
              " {'id': '9b6735d5-3fec-421b-8678-477c99ca09d7',\n",
              "  'runId': '92114148-97d0-4abc-83c7-8d3619a25d83',\n",
              "  'name': 'vehicles',\n",
              "  'timestamp': '2024-11-30T10:01:07.273Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 4, 'triggerExecution': 5},\n",
              "  'stateOperators': [{'operatorName': 'dedupe',\n",
              "    'numRowsTotal': 3607,\n",
              "    'numRowsUpdated': 0,\n",
              "    'allUpdatesTimeMs': 10613,\n",
              "    'numRowsRemoved': 0,\n",
              "    'allRemovalsTimeMs': 7,\n",
              "    'commitTimeMs': 10145,\n",
              "    'memoryUsedBytes': 1580112,\n",
              "    'numRowsDroppedByWatermark': 0,\n",
              "    'numShufflePartitions': 200,\n",
              "    'numStateStoreInstances': 200,\n",
              "    'customMetrics': {'loadedMapCacheHitCount': 0,\n",
              "     'loadedMapCacheMissCount': 0,\n",
              "     'numDroppedDuplicateRows': 414,\n",
              "     'stateOnCurrentVersionSizeBytes': 1551312}}],\n",
              "  'sources': [{'description': 'FileStreamSource[file:/content/landing/vehicles*]',\n",
              "    'startOffset': {'logOffset': 0},\n",
              "    'endOffset': {'logOffset': 0},\n",
              "    'latestOffset': None,\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0}],\n",
              "  'sink': {'description': 'MemorySink', 'numOutputRows': 0}},\n",
              " {'id': '9b6735d5-3fec-421b-8678-477c99ca09d7',\n",
              "  'runId': '92114148-97d0-4abc-83c7-8d3619a25d83',\n",
              "  'name': 'vehicles',\n",
              "  'timestamp': '2024-11-30T10:01:17.286Z',\n",
              "  'batchId': 1,\n",
              "  'numInputRows': 0,\n",
              "  'inputRowsPerSecond': 0.0,\n",
              "  'processedRowsPerSecond': 0.0,\n",
              "  'durationMs': {'latestOffset': 2, 'triggerExecution': 3},\n",
              "  'stateOperators': [{'operatorName': 'dedupe',\n",
              "    'numRowsTotal': 3607,\n",
              "    'numRowsUpdated': 0,\n",
              "    'allUpdatesTimeMs': 10613,\n",
              "    'numRowsRemoved': 0,\n",
              "    'allRemovalsTimeMs': 7,\n",
              "    'commitTimeMs': 10145,\n",
              "    'memoryUsedBytes': 1580112,\n",
              "    'numRowsDroppedByWatermark': 0,\n",
              "    'numShufflePartitions': 200,\n",
              "    'numStateStoreInstances': 200,\n",
              "    'customMetrics': {'loadedMapCacheHitCount': 0,\n",
              "     'loadedMapCacheMissCount': 0,\n",
              "     'numDroppedDuplicateRows': 414,\n",
              "     'stateOnCurrentVersionSizeBytes': 1551312}}],\n",
              "  'sources': [{'description': 'FileStreamSource[file:/content/landing/vehicles*]',\n",
              "    'startOffset': {'logOffset': 0},\n",
              "    'endOffset': {'logOffset': 0},\n",
              "    'latestOffset': None,\n",
              "    'numInputRows': 0,\n",
              "    'inputRowsPerSecond': 0.0,\n",
              "    'processedRowsPerSecond': 0.0}],\n",
              "  'sink': {'description': 'MemorySink', 'numOutputRows': 0}}]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select * from vehicles\").show()"
      ],
      "metadata": {
        "id": "wT9pNrwoXBi4",
        "outputId": "62825b30-3b00-40ce-ebcc-35d62c5f9d9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+--------------------+\n",
            "|bearing|            block_id|current_status|      id|      lat|line_id|      lon|pattern_id|route_id|schedule_relationship|    shift_id|    speed|stop_id|          timestamp|             trip_id|\n",
            "+-------+--------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+--------------------+\n",
            "|    183|                1155| IN_TRANSIT_TO| 42|1155|38.917503|   2626|-9.322189|  2626_0_1|  2626_0|            SCHEDULED|       44537|11.666667| 080448|2024-11-30 09:53:02|2626_0_1|160|1|09...|\n",
            "|      0|                1253|    STOPPED_AT| 42|1253|38.831844|   2017|-9.178019|  2017_0_1|  2017_0|            SCHEDULED|       43844|0.2777778| 070025|2024-11-30 09:52:09|2017_0_1|160|1|09...|\n",
            "|      0|      ESC_SAB_ES1049|    STOPPED_AT| 43|2378| 38.63942|   3103|-9.149403|  3103_0_2|  3103_0|            SCHEDULED|      ES1049|      0.0| 140137|2024-11-30 09:52:39|3103_0_2_0900_092...|\n",
            "|      0|                1254|    STOPPED_AT| 42|1254|38.825783|   2753|-9.162241|  2753_0_1|  2753_0|            SCHEDULED|       46219|      0.0| 070283|2024-11-30 09:52:27|2753_0_1|160|1|09...|\n",
            "|    201|           2_2706-21|   INCOMING_AT| 41|1207| 38.76424|   1623| -9.38322|  1623_1_2|  1623_1|            SCHEDULED|        2744| 9.166667| 172290|2024-11-30 09:52:40|1623_1_2_0930_095...|\n",
            "|     40|           2_2737-21| IN_TRANSIT_TO| 41|1727|38.785305|   1253|-9.466183|  1253_0_3|  1253_0|            SCHEDULED|        2737| 8.333333| 171940|2024-11-30 09:52:15|1253_0_3_0900_092...|\n",
            "|    296|             4002-21|   INCOMING_AT|  42|293|38.810513|   2730|-9.099896|  2730_0_2|  2730_0|            SCHEDULED|        4002|      0.0| 071249|2024-11-30 09:52:09|2730_0_2|2|1|0930...|\n",
            "|    346|           2_2741-21| IN_TRANSIT_TO| 41|1235| 38.73068|   1624|-9.445057|  1624_1_1|  1624_1|            SCHEDULED|        2741|13.611111| 050279|2024-11-30 09:54:08|1624_1_1_0930_095...|\n",
            "|    161|           2_2727-21|    STOPPED_AT| 41|1873|38.742844|   1252|-9.387572|  1252_1_3|  1252_1|            SCHEDULED| 2727+2775P2|      0.0| 171875|2024-11-30 09:54:04|1252_1_3_0830_085...|\n",
            "|    168|           2_2201-21|    STOPPED_AT| 41|1307|38.777172|   1219|-9.294998|  1219_0_2|  1219_0|            SCHEDULED|        2221|0.2777778| 170635|2024-11-30 09:55:43|1219_0_2_0930_095...|\n",
            "|    276|20241130-64020065...| IN_TRANSIT_TO|44|12519|38.523006|   4412| -8.85611|  4412_0_1|  4412_0|            SCHEDULED|112150000007|11.944445| 160002|2024-11-30 09:55:45|4412_0_1|3000|094...|\n",
            "|     51|           2_2622-21| IN_TRANSIT_TO| 41|1322|38.738544|   1718|-9.212061|  1718_0_1|  1718_0|            SCHEDULED|        2622|11.944445| 030763|2024-11-30 09:55:44|1718_0_1_0900_092...|\n",
            "|      0|           2_2422-21|    STOPPED_AT| 41|1712|38.731743|   1528|-9.278102|  1528_0_1|  1528_0|            SCHEDULED|        2422|      0.0| 120555|2024-11-30 09:55:43|1528_0_1_0930_095...|\n",
            "|      0|             4704-21|    STOPPED_AT| 42|2505|38.840603|   2037|-9.161094|  2037_0_3|  2037_0|            SCHEDULED|        4704|      0.0| 070379|2024-11-30 09:56:11|2037_0_3|2|1|0935...|\n",
            "|    167|           2_2625-21|    STOPPED_AT| 41|1328|38.757282|   1716|-9.236093|  1716_0_1|  1716_0|            SCHEDULED|        2625|1.1111112| 030477|2024-11-30 09:56:47|1716_0_1_0930_095...|\n",
            "|      0|      ESC_SAB_ES2033|    STOPPED_AT| 43|2252|38.654488|   3024|-9.165983|  3024_0_2|  3024_0|            SCHEDULED|      ES2033|      0.0| 020729|2024-11-30 09:53:10|3024_0_2_0930_095...|\n",
            "|    247|           2_2311-21|    STOPPED_AT| 41|1221|38.717453|   1638|-9.342676|  1638_3_1|  1638_3|            SCHEDULED|        2320|      0.0| 050468|2024-11-30 09:52:11|1638_3_1_0930_095...|\n",
            "|     85|           2_2310-21|    STOPPED_AT| 41|1219|38.713337|   1638|-9.362506|  1638_3_2|  1638_3|            SCHEDULED|        2310|      2.5| 050440|2024-11-30 09:51:57|1638_3_2_0930_095...|\n",
            "|     24|      ESC_SAB_ES3020| IN_TRANSIT_TO|   43|13|38.432724|   3204|-9.183736|  3204_0_1|  3204_0|            SCHEDULED|      ES3020| 9.722222| 150209|2024-11-30 09:52:09|3204_0_1_0930_095...|\n",
            "|    318|      ESC_SAB_ES2062| IN_TRANSIT_TO| 43|2233| 38.65679|   3013|-9.171152|  3013_0_1|  3013_0|            SCHEDULED|      ES2041|4.7222223| 020088|2024-11-30 09:51:24|3013_0_1_0900_092...|\n",
            "+-------+--------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/bronze"
      ],
      "metadata": {
        "id": "W1BCl7BCXo_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "# watermark is necessary because of the aggregation\n",
        "# importante usar o watermark neste ponto pois não queremos perder dados (pode ser, por exemplo, um requisito de negócio)\n",
        "# Aqui, para todas as operações estou a querer guardar os dados em intervalos de 60s em 60s\n",
        "transformed = stream.withWatermark(\"timestamp\", \"60 seconds\")\n",
        "agg = (transformed\n",
        "       .groupBy(window(transformed.timestamp, \"5 minutes\"), col(\"current_status\"))\n",
        "       .agg(min(transformed.timestamp).alias(\"init_timestamp\"), count(\"*\").alias(\"count\")))\n",
        "\n",
        "def insert_vehicles(df, batch_id):\n",
        "  #df2 = df.groupBy(\"window\").pivot(\"current_status\").sum(\"count\")\n",
        "  # Aqui estamos a utilizar o modo de batch (estamos a utilizar write() e não writeStreaming())\n",
        "  df.write.format(\"parquet\").mode(\"append\").save(\"/content/bronze/vehicles\")\n",
        "\n",
        "# using memory for testing\n",
        "query2 = (agg\n",
        "          .writeStream\n",
        "          .outputMode(\"append\")\n",
        "          # usamos o foreach pois:\n",
        "          # 1. write the output of a streaming query to data sources that do not have an existing streaming sink.\n",
        "          # 2. allows you to apply batch functions to the output data of every micro-batch of the streaming query.\n",
        "          # Temos que passar o método que queremos nestes processos\n",
        "          .foreachBatch(insert_vehicles)\n",
        "          .option(\"checkpointLocation\", \"/content/bronze/checkpoint\")\n",
        "          .trigger(processingTime='20 seconds')\n",
        "          .start())"
      ],
      "metadata": {
        "id": "xyDkRdgLUZZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.read.format(\"parquet\").load(\"/content/bronze/vehicles/*\").show(100, False)"
      ],
      "metadata": {
        "id": "d6xqFWyKdujI",
        "outputId": "78794dc5-db08-468b-c5b2-3ad101451d29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------+--------------+-------------------+-----+\n",
            "|window                                    |current_status|init_timestamp     |count|\n",
            "+------------------------------------------+--------------+-------------------+-----+\n",
            "|{2024-11-29 00:25:00, 2024-11-29 00:30:00}|IN_TRANSIT_TO |2024-11-29 00:29:47|5    |\n",
            "|{2024-11-29 00:10:00, 2024-11-29 00:15:00}|IN_TRANSIT_TO |2024-11-29 00:14:31|18   |\n",
            "|{2024-11-29 00:15:00, 2024-11-29 00:20:00}|IN_TRANSIT_TO |2024-11-29 00:15:02|916  |\n",
            "|{2024-11-29 00:20:00, 2024-11-29 00:25:00}|IN_TRANSIT_TO |2024-11-29 00:20:00|2    |\n",
            "|{2024-11-29 00:15:00, 2024-11-29 00:20:00}|INCOMING_AT   |2024-11-29 00:15:01|308  |\n",
            "|{2024-11-29 00:25:00, 2024-11-29 00:30:00}|INCOMING_AT   |2024-11-29 00:29:13|6    |\n",
            "|{2024-11-29 00:10:00, 2024-11-29 00:15:00}|INCOMING_AT   |2024-11-29 00:14:29|4    |\n",
            "|{2024-11-29 00:20:00, 2024-11-29 00:25:00}|INCOMING_AT   |2024-11-29 00:20:00|2    |\n",
            "|{2024-11-29 00:15:00, 2024-11-29 00:20:00}|STOPPED_AT    |2024-11-29 00:15:00|295  |\n",
            "|{2024-11-29 00:10:00, 2024-11-29 00:15:00}|STOPPED_AT    |2024-11-29 00:14:31|16   |\n",
            "|{2024-11-29 00:25:00, 2024-11-29 00:30:00}|STOPPED_AT    |2024-11-29 00:29:12|10   |\n",
            "+------------------------------------------+--------------+-------------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Report\n",
        "- show vehicles by status in 5-min window time\n",
        "- one line per window time"
      ],
      "metadata": {
        "id": "62oGSmx4S8Ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pivot_data(df: DataFrame):\n",
        "  result = df.orderBy(\"init_timestamp\").groupBy(\"window\").pivot(\"current_status\").sum(\"count\")\n",
        "  result.show(100, False)\n",
        "\n",
        "df = spark.read.format(\"parquet\").load(\"/content/bronze/vehicles/*\")\n",
        "pivot_data(df)"
      ],
      "metadata": {
        "id": "x38lvoysfKLy",
        "outputId": "a061dcff-401d-49da-c906-55f5aef99e1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------+-----------+-------------+----------+\n",
            "|window                                    |INCOMING_AT|IN_TRANSIT_TO|STOPPED_AT|\n",
            "+------------------------------------------+-----------+-------------+----------+\n",
            "|{2024-11-29 00:20:00, 2024-11-29 00:25:00}|2          |2            |NULL      |\n",
            "|{2024-11-29 00:15:00, 2024-11-29 00:20:00}|308        |916          |295       |\n",
            "|{2024-11-29 00:10:00, 2024-11-29 00:15:00}|4          |18           |16        |\n",
            "|{2024-11-29 00:25:00, 2024-11-29 00:30:00}|6          |5            |10        |\n",
            "+------------------------------------------+-----------+-------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query2.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyDwzbdmO29f",
        "outputId": "ff21e3ee-6769-4a80-de42-7bc10cc5ddc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:py4j.clientserver:There was an exception while executing the Python Proxy on the Python Side.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\", line 617, in _call_proxy\n",
            "    return_value = getattr(self.pool[obj_id], method)(*params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyspark/sql/utils.py\", line 120, in call\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyspark/sql/utils.py\", line 117, in call\n",
            "    self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)\n",
            "  File \"<ipython-input-48-9446b2336b0e>\", line 11, in insert_vehicles\n",
            "    df.write.format(\"parquet\").mode(\"append\").save(\"/content/bronze/vehicles\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyspark/sql/readwriter.py\", line 1463, in save\n",
            "    self._jwrite.save(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\", line 1322, in __call__\n",
            "    return_value = get_return_value(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\", line 179, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/protocol.py\", line 326, in get_return_value\n",
            "    raise Py4JJavaError(\n",
            "py4j.protocol.Py4JJavaError: An error occurred while calling o457.save.\n",
            ": java.lang.InterruptedException\n",
            "\tat java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1040)\n",
            "\tat java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1345)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:242)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:258)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:187)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitReady(ThreadUtils.scala:342)\n",
            "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:980)\n",
            "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\n",
            "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeWrite$4(FileFormatWriter.scala:307)\n",
            "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:271)\n",
            "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:304)\n",
            "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:190)\n",
            "\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:190)\n",
            "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\n",
            "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\n",
            "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
            "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
            "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869)\n",
            "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391)\n",
            "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364)\n",
            "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:243)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
            "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
            "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
            "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
            "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
            "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
            "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
            "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
            "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
            "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
            "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
            "\tat com.sun.proxy.$Proxy35.call(Unknown Source)\n",
            "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
            "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
            "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3ETfknUmUeZg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}